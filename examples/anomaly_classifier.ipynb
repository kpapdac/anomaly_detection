{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd87d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from anomaly_detection import detect_anomaly\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca734c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kpapdac'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28dc13fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/kpapdac/anomaly_detection.git\n",
      "  Cloning https://github.com/kpapdac/anomaly_detection.git to /var/tmp/pip-req-build-bxgs0tv8\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/kpapdac/anomaly_detection.git /var/tmp/pip-req-build-bxgs0tv8\n",
      "  Resolved https://github.com/kpapdac/anomaly_detection.git to commit 3efc69924bc759091082ba8dfaf52990daf98d6f\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from anomaly-detection==0.0.1) (1.21.6)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from anomaly-detection==0.0.1) (3.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->anomaly-detection==0.0.1) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->anomaly-detection==0.0.1) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->anomaly-detection==0.0.1) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->anomaly-detection==0.0.1) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->anomaly-detection==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->anomaly-detection==0.0.1) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->anomaly-detection==0.0.1) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->anomaly-detection==0.0.1) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->anomaly-detection==0.0.1) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/kpapdac/anomaly_detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30e2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = pd.read_csv(r'https://github.com/GuansongPang/ADRepository-Anomaly-detection-datasets/raw/main/numerical%20data/DevNet%20datasets/KDD2014_donors_10feat_nomissing_normalised.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89463076",
   "metadata": {},
   "source": [
    "The donors data is taken from KDD Cup 2014 for predicting excitement of projects proposed by K-12 school teachers, in which\n",
    "exceptionally exciting projects are used as anomalies (5.92% data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021d38e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    582616\n",
       "1     36710\n",
       "Name: fully_funded=t, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors.groupby('class')['fully_funded=t'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b0c3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "at_least_1_teacher_referred_donor=t                   3\n",
       "fully_funded=t                                        2\n",
       "at_least_1_green_donation=0                           3\n",
       "great_chat=t                                          2\n",
       "three_or_more_non_teacher_referred_donors=0           3\n",
       "one_non_teacher_referred_donor_giving_100_plus=t      3\n",
       "donation_from_thoughtful_donor=t                      3\n",
       "great_messages_proportion                           102\n",
       "teacher_referred_count                               82\n",
       "non_teacher_referred_count                          135\n",
       "class                                                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f2757",
   "metadata": {},
   "source": [
    "Sample stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2126654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "4694\n",
      "Fold 1:\n",
      "306\n",
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "X = donors.iloc[0:5000,0:donors.shape[1]-1].copy().to_numpy()\n",
    "y = donors.iloc[0:5000,donors.shape[1]-1:donors.shape[1]].copy().to_numpy()\n",
    "groups = donors.iloc[0:5000,donors.shape[1]-1:donors.shape[1]].copy().to_numpy()\n",
    "gss = GroupShuffleSplit(n_splits=2, train_size=.7, random_state=42)\n",
    "X_train_twoclass = []\n",
    "y_train_twoclass = []\n",
    "for i, (train_index, test_index) in enumerate(gss.split(X, y,groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(len(groups[train_index]))\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_train_twoclass.append(X_train)\n",
    "    y_train_twoclass.append(y_train)\n",
    "print(np.concatenate([X_train_twoclass[0],X_train_twoclass[1]]).shape)\n",
    "X_train_m = np.concatenate([X_train_twoclass[0],X_train_twoclass[1]])\n",
    "y_train_m = np.concatenate([y_train_twoclass[0],y_train_twoclass[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3a3b4",
   "metadata": {},
   "source": [
    "OneClassSVM, Isolation Forest, Kmeans, Gaussian MM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac49d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_m.copy()\n",
    "pred_svm = detect_anomaly.runOneClassSVM().fit_predict(X,X)\n",
    "pred_if = detect_anomaly.runIsolationForest().fit_predict(X,X)\n",
    "pred_km = detect_anomaly.runKMeans(2).fit_predict(X,X)\n",
    "pred_gmm = detect_anomaly.runGaussianMixture(2).fit_predict(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e6d70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2512, 2488, 2769, 2231, 1561, 3439, 2210, 2790)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_svm==1).sum(),(pred_svm==-1).sum(), (pred_if==1).sum(),(pred_if==-1).sum(), (pred_km==1).sum(),(pred_km==0).sum(), (pred_gmm[0]==1).sum(),(pred_gmm[0]==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ce721",
   "metadata": {},
   "source": [
    "Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07963954",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'anomaly_detection.detect_anomaly' has no attribute 'NeuralNetwork'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_9044/2689461658.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_anomaly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# x = torch.randn(128, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# y = torch.from_numpy(np.repeat(0,128))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'anomaly_detection.detect_anomaly' has no attribute 'NeuralNetwork'"
     ]
    }
   ],
   "source": [
    "nn_model = detect_anomaly.NeuralNetwork(D_in=X.shape[0],H=30)\n",
    "x = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y)\n",
    "# x = torch.randn(128, 20)\n",
    "# y = torch.from_numpy(np.repeat(0,128))\n",
    "X_y = [(x[i],y[i]) for i in range(len(x))]\n",
    "dataset_ = loader.FeatureClusterDataset(X_y)\n",
    "train_dataloader = DataLoader(dataset_, batch_size=64)\n",
    "opt = detect_anomaly.optimizeNN(train_dataloader, nn_model, learning_rate=1e-3, batch_size=64, epochs=5)\n",
    "opt.train_loop()\n",
    "opt.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0eb7762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IsolationForest',\n",
       " 'KMeans',\n",
       " 'OneClassSVM',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'mixture',\n",
       " 'runGaussianMixture',\n",
       " 'runIsolationForest',\n",
       " 'runKMeans',\n",
       " 'runOneClassSVM']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(detect_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515017db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
